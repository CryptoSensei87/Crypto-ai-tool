import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Load data from CSV files
def load_data(file_path):
    logging.info(f"Loading data from {file_path}")
    return pd.read_csv(file_path)

# Handle missing data
def clean_data(df, method='drop', fill_value=None):
    if method == 'drop':
        logging.info("Dropping rows with missing values")
        df = df.dropna()
    elif method == 'fill':
        logging.info(f"Filling missing values with {fill_value}")
        df = df.fillna(fill_value)
    return df

# Normalize data
def normalize_data(df, columns):
    logging.info(f"Normalizing columns: {columns}")
    scaler = MinMaxScaler()
    df[columns] = scaler.fit_transform(df[columns])
    return df

# Example feature engineering
def create_features(df):
    logging.info("Creating new features")
    df['price_diff'] = df['close'] - df['open']
    df['high_low_diff'] = df['high'] - df['low']
    df['volatility'] = (df['high'] - df['low']) / df['open']
    return df

def main():
    # Load data
    df = load_data('crypto_data.csv')
    
    # Clean data
    df = clean_data(df, method='fill', fill_value=0)
    
    # Normalize data
    df = normalize_data(df, ['open', 'high', 'low', 'close', 'volume'])
    
    # Feature engineering
    df = create_features(df)
    
    # Save preprocessed data
    output_file = 'preprocessed_crypto_data.csv'
    df.to_csv(output_file, index=False)
    logging.info(f"Data preprocessing complete. Preprocessed data saved to '{output_file}'.")

if __name__ == "__main__":
    main()